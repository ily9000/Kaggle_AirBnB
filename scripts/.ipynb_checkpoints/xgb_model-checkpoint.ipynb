{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import kaggle_xgb\n",
    "import calc_ndcg\n",
    "#from sklearn.grid_search import ParameterGrid\n",
    "import pickle\n",
    "import dataEngr\n",
    "reload(dataEngr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in just the testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbInput = dataEngr.clfInput()\n",
    "xgbInput.get_sessionsFtr()\n",
    "xgbInput.users_ftrEng()\n",
    "xgbInput.one_hot()\n",
    "#xgbInput.binarize_targets()\n",
    "xgbInput.split_data(update_trainDf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "condition = 'dac_year == 2014 & action_counts != -1'\n",
    "len(xgbInput.trainDf.query(condition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns before one hot encoding 369\n",
      "number of columns after one hot encoding 468\n",
      "0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.168629\teval-error:0.139420\n",
      "[1]\ttrain-error:0.166919\teval-error:0.138713\n",
      "[2]\ttrain-error:0.165806\teval-error:0.137046\n",
      "[3]\ttrain-error:0.165314\teval-error:0.137009\n",
      "[4]\ttrain-error:0.165057\teval-error:0.137143\n",
      "[5]\ttrain-error:0.164905\teval-error:0.137027\n",
      "[6]\ttrain-error:0.164749\teval-error:0.137254\n",
      "[7]\ttrain-error:0.164594\teval-error:0.136866\n",
      "[8]\ttrain-error:0.164238\teval-error:0.136497\n",
      "[9]\ttrain-error:0.164058\teval-error:0.136797\n",
      "[10]\ttrain-error:0.163809\teval-error:0.136145\n",
      "[11]\ttrain-error:0.163609\teval-error:0.136209\n",
      "[12]\ttrain-error:0.163483\teval-error:0.135998\n",
      "[13]\ttrain-error:0.163346\teval-error:0.136018\n",
      "[14]\ttrain-error:0.163142\teval-error:0.135959\n",
      "[15]\ttrain-error:0.162913\teval-error:0.136072\n",
      "[16]\ttrain-error:0.162797\teval-error:0.135702\n",
      "[17]\ttrain-error:0.162616\teval-error:0.136168\n",
      "[18]\ttrain-error:0.162492\teval-error:0.136125\n",
      "[19]\ttrain-error:0.162344\teval-error:0.135776\n",
      "[20]\ttrain-error:0.162238\teval-error:0.135999\n",
      "[21]\ttrain-error:0.162075\teval-error:0.135820\n",
      "[22]\ttrain-error:0.161819\teval-error:0.135742\n",
      "[23]\ttrain-error:0.161681\teval-error:0.135584\n",
      "[24]\ttrain-error:0.161584\teval-error:0.135613\n",
      "[25]\ttrain-error:0.161319\teval-error:0.135593\n",
      "[26]\ttrain-error:0.161333\teval-error:0.135481\n",
      "[27]\ttrain-error:0.161219\teval-error:0.135671\n",
      "[28]\ttrain-error:0.161068\teval-error:0.135523\n",
      "[29]\ttrain-error:0.160884\teval-error:0.135661\n",
      "[30]\ttrain-error:0.160744\teval-error:0.135522\n",
      "[31]\ttrain-error:0.160604\teval-error:0.135576\n",
      "[32]\ttrain-error:0.160514\teval-error:0.135608\n",
      "[33]\ttrain-error:0.160378\teval-error:0.135414\n",
      "[34]\ttrain-error:0.160228\teval-error:0.135378\n",
      "[35]\ttrain-error:0.160012\teval-error:0.135190\n",
      "[36]\ttrain-error:0.159930\teval-error:0.135114\n",
      "[37]\ttrain-error:0.159826\teval-error:0.135074\n",
      "[38]\ttrain-error:0.159648\teval-error:0.135194\n",
      "[39]\ttrain-error:0.159587\teval-error:0.135073\n",
      "[40]\ttrain-error:0.159484\teval-error:0.135229\n",
      "[41]\ttrain-error:0.159249\teval-error:0.134979\n",
      "[42]\ttrain-error:0.159136\teval-error:0.135301\n",
      "[43]\ttrain-error:0.158980\teval-error:0.135324\n",
      "[44]\ttrain-error:0.158873\teval-error:0.135532\n",
      "[45]\ttrain-error:0.158810\teval-error:0.135587\n",
      "[46]\ttrain-error:0.158634\teval-error:0.135169\n",
      "[47]\ttrain-error:0.158513\teval-error:0.135012\n",
      "[48]\ttrain-error:0.158424\teval-error:0.134966\n",
      "[49]\ttrain-error:0.158264\teval-error:0.135056\n",
      "[50]\ttrain-error:0.158134\teval-error:0.135246\n",
      "[51]\ttrain-error:0.158065\teval-error:0.135110\n",
      "[52]\ttrain-error:0.157901\teval-error:0.135060\n",
      "[53]\ttrain-error:0.157846\teval-error:0.134953\n",
      "[54]\ttrain-error:0.157701\teval-error:0.135113\n",
      "[55]\ttrain-error:0.157544\teval-error:0.135186\n",
      "[56]\ttrain-error:0.157467\teval-error:0.135323\n",
      "[57]\ttrain-error:0.157336\teval-error:0.135242\n",
      "[58]\ttrain-error:0.157210\teval-error:0.135121\n",
      "[59]\ttrain-error:0.157091\teval-error:0.134964\n",
      "[60]\ttrain-error:0.156984\teval-error:0.135118\n",
      "[61]\ttrain-error:0.156906\teval-error:0.135143\n",
      "[62]\ttrain-error:0.156776\teval-error:0.135109\n",
      "[63]\ttrain-error:0.156652\teval-error:0.134885\n",
      "[64]\ttrain-error:0.156582\teval-error:0.134633\n",
      "[65]\ttrain-error:0.156486\teval-error:0.134712\n",
      "[66]\ttrain-error:0.156346\teval-error:0.134860\n",
      "[67]\ttrain-error:0.156178\teval-error:0.134776\n",
      "[68]\ttrain-error:0.156025\teval-error:0.134767\n",
      "[69]\ttrain-error:0.155985\teval-error:0.134880\n",
      "[70]\ttrain-error:0.155850\teval-error:0.135070\n",
      "[71]\ttrain-error:0.155751\teval-error:0.135093\n",
      "[72]\ttrain-error:0.155641\teval-error:0.135017\n",
      "[73]\ttrain-error:0.155580\teval-error:0.134972\n",
      "[74]\ttrain-error:0.155519\teval-error:0.134996\n",
      "[75]\ttrain-error:0.155413\teval-error:0.134958\n",
      "[76]\ttrain-error:0.155326\teval-error:0.135101\n",
      "[77]\ttrain-error:0.155254\teval-error:0.135275\n",
      "[78]\ttrain-error:0.155134\teval-error:0.135324\n",
      "[79]\ttrain-error:0.155035\teval-error:0.135114\n",
      "[80]\ttrain-error:0.154975\teval-error:0.134940\n",
      "[81]\ttrain-error:0.154833\teval-error:0.135092\n",
      "[82]\ttrain-error:0.154730\teval-error:0.134844\n",
      "[83]\ttrain-error:0.154644\teval-error:0.134760\n",
      "[84]\ttrain-error:0.154466\teval-error:0.134841\n",
      "[85]\ttrain-error:0.154390\teval-error:0.135035\n",
      "[86]\ttrain-error:0.154282\teval-error:0.134987\n",
      "[87]\ttrain-error:0.154170\teval-error:0.135009\n",
      "[88]\ttrain-error:0.154098\teval-error:0.135013\n",
      "[89]\ttrain-error:0.154012\teval-error:0.134778\n",
      "[90]\ttrain-error:0.153958\teval-error:0.134885\n",
      "[91]\ttrain-error:0.153869\teval-error:0.134669\n",
      "[92]\ttrain-error:0.153755\teval-error:0.134607\n",
      "[93]\ttrain-error:0.153689\teval-error:0.134675\n",
      "[94]\ttrain-error:0.153614\teval-error:0.134540\n",
      "[95]\ttrain-error:0.153541\teval-error:0.134647\n",
      "[96]\ttrain-error:0.153487\teval-error:0.134774\n",
      "[97]\ttrain-error:0.153361\teval-error:0.134796\n",
      "[98]\ttrain-error:0.153277\teval-error:0.134676\n",
      "[99]\ttrain-error:0.153210\teval-error:0.135613\n",
      "[0]\ttrain-error:0.172990\teval-error:0.152107\n",
      "[1]\ttrain-error:0.171394\teval-error:0.148949\n",
      "[2]\ttrain-error:0.170799\teval-error:0.147969\n",
      "[3]\ttrain-error:0.170410\teval-error:0.148104\n",
      "[4]\ttrain-error:0.169656\teval-error:0.147558\n",
      "[5]\ttrain-error:0.168799\teval-error:0.146812\n",
      "[6]\ttrain-error:0.168089\teval-error:0.146657\n",
      "[7]\ttrain-error:0.167044\teval-error:0.146587\n",
      "[8]\ttrain-error:0.167005\teval-error:0.146440\n",
      "[9]\ttrain-error:0.166005\teval-error:0.146580\n",
      "[10]\ttrain-error:0.164562\teval-error:0.144971\n",
      "[11]\ttrain-error:0.164246\teval-error:0.144935\n",
      "[12]\ttrain-error:0.164024\teval-error:0.144560\n",
      "[13]\ttrain-error:0.163626\teval-error:0.144564\n",
      "[14]\ttrain-error:0.163419\teval-error:0.144594\n",
      "[15]\ttrain-error:0.163203\teval-error:0.143685\n",
      "[16]\ttrain-error:0.162984\teval-error:0.143489\n",
      "[17]\ttrain-error:0.162784\teval-error:0.143090\n",
      "[18]\ttrain-error:0.162562\teval-error:0.143329\n",
      "[19]\ttrain-error:0.162390\teval-error:0.142827\n",
      "[20]\ttrain-error:0.162153\teval-error:0.142696\n",
      "[21]\ttrain-error:0.161851\teval-error:0.142814\n",
      "[22]\ttrain-error:0.161794\teval-error:0.142625\n",
      "[23]\ttrain-error:0.161585\teval-error:0.142689\n",
      "[24]\ttrain-error:0.161348\teval-error:0.142252\n",
      "[25]\ttrain-error:0.161179\teval-error:0.142245\n",
      "[26]\ttrain-error:0.161055\teval-error:0.141889\n",
      "[27]\ttrain-error:0.160855\teval-error:0.141866\n",
      "[28]\ttrain-error:0.160671\teval-error:0.141598\n",
      "[29]\ttrain-error:0.160546\teval-error:0.141575\n",
      "[30]\ttrain-error:0.160387\teval-error:0.141442\n",
      "[31]\ttrain-error:0.160206\teval-error:0.141609\n",
      "[32]\ttrain-error:0.160080\teval-error:0.141689\n",
      "[33]\ttrain-error:0.159942\teval-error:0.141849\n",
      "[34]\ttrain-error:0.159706\teval-error:0.141725\n",
      "[35]\ttrain-error:0.159632\teval-error:0.141834\n",
      "[36]\ttrain-error:0.159517\teval-error:0.141688\n",
      "[37]\ttrain-error:0.159403\teval-error:0.141715\n",
      "[38]\ttrain-error:0.159242\teval-error:0.141529\n",
      "[39]\ttrain-error:0.159066\teval-error:0.141505\n",
      "[40]\ttrain-error:0.159008\teval-error:0.141494\n",
      "[41]\ttrain-error:0.158904\teval-error:0.141247\n",
      "[42]\ttrain-error:0.158799\teval-error:0.141130\n",
      "[43]\ttrain-error:0.158712\teval-error:0.141384\n",
      "[44]\ttrain-error:0.158525\teval-error:0.141154\n",
      "[45]\ttrain-error:0.158397\teval-error:0.140975\n",
      "[46]\ttrain-error:0.158304\teval-error:0.140863\n",
      "[47]\ttrain-error:0.158225\teval-error:0.141033\n",
      "[48]\ttrain-error:0.158035\teval-error:0.140921\n",
      "[49]\ttrain-error:0.157890\teval-error:0.140725\n",
      "[50]\ttrain-error:0.157793\teval-error:0.140881\n",
      "[51]\ttrain-error:0.157665\teval-error:0.140731\n",
      "[52]\ttrain-error:0.157516\teval-error:0.140843\n",
      "[53]\ttrain-error:0.157398\teval-error:0.140606\n",
      "[54]\ttrain-error:0.157310\teval-error:0.140586\n",
      "[55]\ttrain-error:0.157200\teval-error:0.141072\n",
      "[56]\ttrain-error:0.157074\teval-error:0.140993\n",
      "[57]\ttrain-error:0.156947\teval-error:0.141209\n",
      "[58]\ttrain-error:0.156826\teval-error:0.141003\n",
      "[59]\ttrain-error:0.156694\teval-error:0.141069\n",
      "[60]\ttrain-error:0.156586\teval-error:0.141070\n",
      "[61]\ttrain-error:0.156505\teval-error:0.141220\n",
      "[62]\ttrain-error:0.156285\teval-error:0.141122\n",
      "[63]\ttrain-error:0.156229\teval-error:0.141173\n",
      "[64]\ttrain-error:0.156155\teval-error:0.141248\n",
      "[65]\ttrain-error:0.155989\teval-error:0.141130\n",
      "[66]\ttrain-error:0.155893\teval-error:0.141312\n",
      "[67]\ttrain-error:0.155846\teval-error:0.141173\n",
      "[68]\ttrain-error:0.155770\teval-error:0.141361\n",
      "[69]\ttrain-error:0.155665\teval-error:0.141452\n",
      "[70]\ttrain-error:0.155587\teval-error:0.141024\n",
      "[71]\ttrain-error:0.155492\teval-error:0.141103\n",
      "[72]\ttrain-error:0.155339\teval-error:0.140855\n",
      "[73]\ttrain-error:0.155297\teval-error:0.140922\n",
      "[74]\ttrain-error:0.155208\teval-error:0.140823\n",
      "[75]\ttrain-error:0.155047\teval-error:0.140953\n",
      "[76]\ttrain-error:0.154968\teval-error:0.140945\n",
      "[77]\ttrain-error:0.154852\teval-error:0.141094\n",
      "[78]\ttrain-error:0.154738\teval-error:0.141369\n",
      "[79]\ttrain-error:0.154652\teval-error:0.141577\n",
      "[80]\ttrain-error:0.154603\teval-error:0.141520\n",
      "[81]\ttrain-error:0.154516\teval-error:0.141611\n",
      "[82]\ttrain-error:0.154394\teval-error:0.141149\n",
      "[83]\ttrain-error:0.154257\teval-error:0.141275\n",
      "[84]\ttrain-error:0.154201\teval-error:0.141476\n",
      "[85]\ttrain-error:0.154067\teval-error:0.141244\n",
      "[86]\ttrain-error:0.153958\teval-error:0.140930\n",
      "[87]\ttrain-error:0.153850\teval-error:0.141177\n",
      "[88]\ttrain-error:0.153782\teval-error:0.141130\n",
      "[89]\ttrain-error:0.153683\teval-error:0.141409\n",
      "[90]\ttrain-error:0.153584\teval-error:0.141449\n",
      "[91]\ttrain-error:0.153519\teval-error:0.141376\n",
      "[92]\ttrain-error:0.153403\teval-error:0.141248\n",
      "[93]\ttrain-error:0.153285\teval-error:0.141276\n",
      "[94]\ttrain-error:0.153133\teval-error:0.141205\n",
      "[95]\ttrain-error:0.153086\teval-error:0.141198\n",
      "[96]\ttrain-error:0.152974\teval-error:0.141022\n",
      "[97]\ttrain-error:0.152891\teval-error:0.141030\n",
      "[98]\ttrain-error:0.152821\teval-error:0.140982\n",
      "[99]\ttrain-error:0.152761\teval-error:0.140979\n",
      "[0]\ttrain-error:0.177227\teval-error:0.153404\n",
      "[1]\ttrain-error:0.172861\teval-error:0.150177\n",
      "[2]\ttrain-error:0.172291\teval-error:0.149287\n",
      "[3]\ttrain-error:0.171406\teval-error:0.148420\n",
      "[4]\ttrain-error:0.167374\teval-error:0.145897\n",
      "[5]\ttrain-error:0.165920\teval-error:0.144734\n",
      "[6]\ttrain-error:0.165357\teval-error:0.143826\n",
      "[7]\ttrain-error:0.164932\teval-error:0.142618\n",
      "[8]\ttrain-error:0.164738\teval-error:0.142912\n",
      "[9]\ttrain-error:0.164240\teval-error:0.142314\n",
      "[10]\ttrain-error:0.163962\teval-error:0.141445\n",
      "[11]\ttrain-error:0.163666\teval-error:0.141343\n",
      "[12]\ttrain-error:0.163337\teval-error:0.140928\n",
      "[13]\ttrain-error:0.163287\teval-error:0.141064\n",
      "[14]\ttrain-error:0.163084\teval-error:0.141009\n",
      "[15]\ttrain-error:0.162776\teval-error:0.140519\n",
      "[16]\ttrain-error:0.162622\teval-error:0.140265\n",
      "[17]\ttrain-error:0.162413\teval-error:0.140242\n",
      "[18]\ttrain-error:0.162322\teval-error:0.140083\n",
      "[19]\ttrain-error:0.162109\teval-error:0.140214\n",
      "[20]\ttrain-error:0.161903\teval-error:0.140118\n",
      "[21]\ttrain-error:0.161729\teval-error:0.140334\n",
      "[22]\ttrain-error:0.161669\teval-error:0.140323\n",
      "[23]\ttrain-error:0.161524\teval-error:0.140483\n",
      "[24]\ttrain-error:0.161422\teval-error:0.140256\n",
      "[25]\ttrain-error:0.161248\teval-error:0.140290\n",
      "[26]\ttrain-error:0.161075\teval-error:0.140124\n",
      "[27]\ttrain-error:0.160937\teval-error:0.140311\n",
      "[28]\ttrain-error:0.160792\teval-error:0.140183\n",
      "[29]\ttrain-error:0.160691\teval-error:0.139989\n",
      "[30]\ttrain-error:0.160629\teval-error:0.140362\n",
      "[31]\ttrain-error:0.160509\teval-error:0.140596\n",
      "[32]\ttrain-error:0.160346\teval-error:0.140519\n",
      "[33]\ttrain-error:0.160215\teval-error:0.140170\n",
      "[34]\ttrain-error:0.160130\teval-error:0.139878\n",
      "[35]\ttrain-error:0.160010\teval-error:0.139951\n",
      "[36]\ttrain-error:0.159923\teval-error:0.140112\n",
      "[37]\ttrain-error:0.159819\teval-error:0.140459\n",
      "[38]\ttrain-error:0.159702\teval-error:0.140419\n",
      "[39]\ttrain-error:0.159520\teval-error:0.140485\n",
      "[40]\ttrain-error:0.159389\teval-error:0.140362\n",
      "[41]\ttrain-error:0.159274\teval-error:0.140454\n",
      "[42]\ttrain-error:0.159106\teval-error:0.140148\n",
      "[43]\ttrain-error:0.159000\teval-error:0.140287\n",
      "[44]\ttrain-error:0.158898\teval-error:0.140419\n",
      "[45]\ttrain-error:0.158707\teval-error:0.140334\n",
      "[46]\ttrain-error:0.158694\teval-error:0.140143\n",
      "[47]\ttrain-error:0.158520\teval-error:0.140071\n",
      "[48]\ttrain-error:0.158403\teval-error:0.139869\n",
      "[49]\ttrain-error:0.158346\teval-error:0.139912\n",
      "[50]\ttrain-error:0.158217\teval-error:0.139987\n",
      "[51]\ttrain-error:0.158121\teval-error:0.140000\n",
      "[52]\ttrain-error:0.158044\teval-error:0.140174\n",
      "[53]\ttrain-error:0.157932\teval-error:0.140166\n",
      "[54]\ttrain-error:0.157792\teval-error:0.140078\n",
      "[55]\ttrain-error:0.157593\teval-error:0.140152\n",
      "[56]\ttrain-error:0.157477\teval-error:0.140116\n",
      "[57]\ttrain-error:0.157329\teval-error:0.140266\n",
      "[58]\ttrain-error:0.157277\teval-error:0.140280\n",
      "[59]\ttrain-error:0.157138\teval-error:0.140491\n"
     ]
    }
   ],
   "source": [
    "%run -i custom_paramsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i run_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {'num_class': 12, 'objective': 'multi:softprob', 'seed': 0}\n",
    "param['eta'] = 0.20\n",
    "param['max_depth'] = 6\n",
    "param['subsample'] = .5\n",
    "param['colsample_bytree'] = .8\n",
    "xgbresults = {}\n",
    "cv_train = pd.read_pickle('cv_results/actions_e20/train_err.p')\n",
    "cv_valid = pd.read_pickle('cv_results/actions_e20/validate_err.p')\n",
    "nrounds = 40\n",
    "for train_indx, valid_indx in cv_bydate(xgbInput):\n",
    "    dtrain = xgb.DMatrix(xgbInput.train_X[train_indx], label = xgbInput.train_Y[train_indx],\n",
    "                missing = -1)\n",
    "    dvalid = xgb.DMatrix(xgbInput.train_X[valid_indx], label = xgbInput.train_Y[valid_indx],\n",
    "                missing = -1)\n",
    "    evallist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(param, dtrain, nrounds, evallist, feval = calc_ndcg.evalerror, evals_result = xgbresults)\n",
    "    cv_train = pd.concat([cv_train, pd.Series(xgbresults['train']['error'])], axis = 1)\n",
    "    cv_valid = pd.concat([cv_valid, pd.Series(xgbresults['eval']['error'])], axis = 1)\n",
    "    pd.concat([param_err, cv_train.mean(axis = 1)]\n",
    "    pd.concat([cv_valid.mean(axis = 1)])\n",
    "pd.to_pickle(cv_train, 'cv_results/actions_e20/train_err.p')\n",
    "pd.to_pickle(cv_valid, 'cv_results/actions_e20/validate_err.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cv_sessions(xgbInput):\n",
    "    \"\"\"Cross-validation on a subset of training data which meets a condition\"\"\"\n",
    "    \n",
    "    condition = 'dac_year == 2014 & action_counts != -1'\n",
    "    idx = np.nonzero(xgbInput.trainDf.index.isin(xgbInput.trainDf.query(condition).index))\n",
    "    idx = idx[0]\n",
    "    np.random.shuffle(idx[0])\n",
    "    n = len(idx)\n",
    "    \n",
    "    for i in range(0, kfolds):\n",
    "        idx[0]\n",
    "        \n",
    "def cv_bydate(xgbInput):\n",
    "    \"\"\"Select folds for cross validation as all cases that occurred in a given with month \n",
    "    in 2014, with sessions data.\n",
    "    Only cases in 2014 have sessions data and the last test case is on June 30.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(4,7):\n",
    "        condition = 'dac_year == 2014 & dac_month == @i & action_counts != -1'\n",
    "        valid_mask = xgbInput.trainDf.index.isin(xgbInput.trainDf.query(condition).index)\n",
    "        valid_indx = np.where(valid_mask)[0]\n",
    "        train_indx = np.where(~valid_mask)[0]\n",
    "        yield train_indx, valid_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.read_pickle('cv_results/sessions_e20_25n/validate_err.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = pd.read_pickle('cv_results/actions_e20/validate_err.p')\n",
    "a = a.astype(float)\n",
    "a['mean'] = a.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_tr_browsers = []\n",
    "null_testbrowsers = []\n",
    "for i in train_data.first_browser.unique():\n",
    "    if i not in test_data.first_browser.unique():\n",
    "        null_tr_browsers.append(i)\n",
    "for i in test_data.first_browser.unique():\n",
    "    if i not in train_data.first_browser.unique():\n",
    "        null_testbrowsers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run run_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(av<14, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av = xgbInput.allDf.age.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../xgbmodels/actions2_e16_90n.p') as f:\n",
    "    bst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbInput.allDf.columns[xgbInput.allDf.columns.str.contains('book')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "features = sorted(bst.get_fscore().items(), key = lambda x: x[1], reverse = True)\n",
    "[(feat, xgbInput.allDf.columns[int(feat[1:])], score) for feat, score in features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
