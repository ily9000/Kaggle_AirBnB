{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import kaggle_xgb\n",
    "import calc_ndcg\n",
    "#from sklearn.grid_search import ParameterGrid\n",
    "import pickle\n",
    "import dataEngr\n",
    "reload(dataEngr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in just the testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgbInput = dataEngr.clfInput()\n",
    "xgbInput.get_sessionsFtr()\n",
    "xgbInput.users_ftrEng()\n",
    "xgbInput.one_hot()\n",
    "#xgbInput.binarize_targets()\n",
    "xgbInput.split_data(update_trainDf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088685</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.086748</td>\n",
       "      <td>0.000393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.087984</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.086076</td>\n",
       "      <td>0.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.087624</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.087582</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.085653</td>\n",
       "      <td>0.000255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.087591</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.085539</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.087420</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.085399</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.087373</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.085277</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.087409</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.085160</td>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.087391</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.085047</td>\n",
       "      <td>0.000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.087428</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.084969</td>\n",
       "      <td>0.000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.087304</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.084842</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.087365</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.084774</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.087315</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.084703</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.087392</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>0.084621</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.087315</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.084536</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.087312</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.084463</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.087282</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.084387</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.087175</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.084293</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.087102</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.084212</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.087157</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.084142</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.087172</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.084068</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.087177</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.083974</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.087167</td>\n",
       "      <td>0.001403</td>\n",
       "      <td>0.083893</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.087122</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.083822</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.087102</td>\n",
       "      <td>0.001456</td>\n",
       "      <td>0.083747</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.087021</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.083640</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.087083</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.083589</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.086964</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.083511</td>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.087030</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.083430</td>\n",
       "      <td>0.000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.086943</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.083326</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0          0.088685        0.001540          0.086748         0.000393\n",
       "1          0.087984        0.001391          0.086076         0.000280\n",
       "2          0.087624        0.001463          0.085826         0.000297\n",
       "3          0.087582        0.001476          0.085653         0.000255\n",
       "4          0.087591        0.001436          0.085539         0.000260\n",
       "5          0.087420        0.001403          0.085399         0.000254\n",
       "6          0.087373        0.001349          0.085277         0.000239\n",
       "7          0.087409        0.001436          0.085160         0.000203\n",
       "8          0.087391        0.001334          0.085047         0.000234\n",
       "9          0.087428        0.001331          0.084969         0.000231\n",
       "10         0.087304        0.001320          0.084842         0.000245\n",
       "11         0.087365        0.001312          0.084774         0.000242\n",
       "12         0.087315        0.001204          0.084703         0.000260\n",
       "13         0.087392        0.001305          0.084621         0.000211\n",
       "14         0.087315        0.001278          0.084536         0.000208\n",
       "15         0.087312        0.001255          0.084463         0.000188\n",
       "16         0.087282        0.001258          0.084387         0.000189\n",
       "17         0.087175        0.001308          0.084293         0.000187\n",
       "18         0.087102        0.001248          0.084212         0.000200\n",
       "19         0.087157        0.001320          0.084142         0.000221\n",
       "20         0.087172        0.001329          0.084068         0.000211\n",
       "21         0.087177        0.001362          0.083974         0.000206\n",
       "22         0.087167        0.001403          0.083893         0.000235\n",
       "23         0.087122        0.001418          0.083822         0.000235\n",
       "24         0.087102        0.001456          0.083747         0.000247\n",
       "25         0.087021        0.001425          0.083640         0.000232\n",
       "26         0.087083        0.001405          0.083589         0.000257\n",
       "27         0.086964        0.001388          0.083511         0.000252\n",
       "28         0.087030        0.001389          0.083430         0.000232\n",
       "29         0.086943        0.001362          0.083326         0.000235"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns before one hot encoding 369\n",
      "number of columns after one hot encoding"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 17 rounds.\n",
      "Stopping. Best iteration: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 468\n"
     ]
    }
   ],
   "source": [
    "%run -i actionsXgb.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../xgbmodels/actions2_e13_96n.p') as f:\n",
    "    bst = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = sorted(bst.get_fscore().items(), key = lambda x: x[1], reverse = True)\n",
    "[(feat, xgbInput.allDf.columns[int(feat[1:])], score) for feat, score in features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
