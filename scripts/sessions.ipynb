{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "#import graphviz\n",
    "from sklearn.cross_validation import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "import sys\n",
    "import kaggle_xgb\n",
    "import calc_ndcg\n",
    "from sklearn.grid_search import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in just the testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_subset = pd.read_csv('../data/train_users_2.csv', nrows = 100000, index_col='id')\n",
    "train_data = pd.read_csv('../data/train_users_2.csv', index_col = 'id')\n",
    "test_data = pd.read_csv('../data/test_users.csv', index_col = 'id')\n",
    "sessions = pd.read_csv('../data/sessions.csv')\n",
    "#age = pd.read_csv('../data/age_gender_bkts.csv')\n",
    "#countries = pd.read_csv('../data/countries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_df is a pickled obect where the training and test has already been concatenated onall columns except 'country_destination'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessions.dropna(subset=['user_id'], inplace = True)\n",
    "\n",
    "sessions_tr = sessions[sessions.user_id.isin(train_data.index)]\n",
    "sessions_test = sessions[sessions.user_id.isin(test_data.index)]\n",
    "a_ignore = set(sessions_tr.action.unique()) ^ set(sessions_test.action.unique())\n",
    "#sessions.groupby('action')['action_detail']\n",
    "\n",
    "#set(sessions_test.action_detail.unique()) ^ set(sessions_tr.action_detail.unique())\n",
    "#sessions_test.action_detail.unique()\n",
    "#sessions_tr.action_detail.unique()\n",
    "#train_data['date_account_created'] = pd.to_datetime(train_data.date_account_created)\n",
    "#x = train_data[train_data.date_account_created>='2014']\n",
    "#train_data[train_data.index.isin(sessions_tr.user_id)].timestamp_first_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284848     6udv3scuxe\n",
       "284944     6udv3scuxe\n",
       "3657667    yxf0sm9sbw\n",
       "3657670    yxf0sm9sbw\n",
       "3657671    yxf0sm9sbw\n",
       "Name: user_id, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#s = sessions.groupby('action')['action_type'].nunique()\n",
    "s[s>1]\n",
    "sessions_tr[sessions_tr.action == 'approve'].user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique actions with more than 50: 206\n"
     ]
    }
   ],
   "source": [
    "actions50 = [sessions_test.groupby('action')['user_id'].nunique() >50]\n",
    "print 'Number of unique actions with more than 50 users:', np.sum(sessions_test.groupby('action')['user_id'].nunique()>50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique actions with just one action type:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the actions with just one action type and one action detail.\n",
    "print 'Number of unique actions with just one action type:'\n",
    "np.sum(sessions_test.groupby('action')['action_detail'].nunique()==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "10                                    True\n",
       "11                                    True\n",
       "12                                    True\n",
       "15                                    True\n",
       "about_us                              True\n",
       "accept_decline                        True\n",
       "account                               True\n",
       "acculynk_bin_check_failed             True\n",
       "acculynk_bin_check_success            True\n",
       "acculynk_load_pin_pad                 True\n",
       "acculynk_pin_pad_error                True\n",
       "acculynk_pin_pad_inactive             True\n",
       "acculynk_pin_pad_success              True\n",
       "acculynk_session_obtained             True\n",
       "active                                True\n",
       "add_business_address_colorbox         True\n",
       "add_guest_colorbox                    True\n",
       "add_guests                            True\n",
       "add_note                              True\n",
       "agree_terms_check                     True\n",
       "agree_terms_uncheck                   True\n",
       "airbnb_picks                          True\n",
       "ajax_check_dates                      True\n",
       "ajax_google_translate                 True\n",
       "ajax_google_translate_description     True\n",
       "ajax_google_translate_reviews         True\n",
       "ajax_image_upload                     True\n",
       "ajax_lwlb_contact                     True\n",
       "ajax_payout_edit                      True\n",
       "ajax_payout_options_by_country        True\n",
       "                                     ...  \n",
       "toggle_availability                   True\n",
       "toggle_starred_thread                 True\n",
       "top_destinations                      True\n",
       "tos_confirm                           True\n",
       "track_activity                       False\n",
       "track_page_view                      False\n",
       "transaction_history                   True\n",
       "transaction_history_paginated         True\n",
       "travel_plans_current                  True\n",
       "travel_plans_previous                 True\n",
       "trust                                 True\n",
       "unavailabilities                      True\n",
       "united-states                         True\n",
       "unsubscribe                           True\n",
       "update                               False\n",
       "update_cached                         True\n",
       "update_country_of_residence           True\n",
       "update_friends_display                True\n",
       "update_hide_from_search_engines       True\n",
       "update_notifications                  True\n",
       "update_reservation_requirements       True\n",
       "upload                                True\n",
       "uptodate                             False\n",
       "verify                                True\n",
       "view                                  True\n",
       "views                                 True\n",
       "webcam_upload                         True\n",
       "weibo_signup_referral_finish          True\n",
       "why_host                              True\n",
       "zendesk_login_jwt                     True\n",
       "Name: action_detail, dtype: bool"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_test.groupby('action')['action_detail'].nunique()==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "unkvmpwxo2      NDF\n",
       "2pw9yjm8aq    other\n",
       "ckkcg778ej      NDF\n",
       "3n3wz1i5y6       US\n",
       "qdzx8bye52      NDF\n",
       "kv5nk5t1bq      NDF\n",
       "hgao67zp6q      NDF\n",
       "dywez4oem4      NDF\n",
       "6k8ov8dr9k      NDF\n",
       "98jeibnoq6       FR\n",
       "w7kxmjecn9      NDF\n",
       "6rg5dn6y92      NDF\n",
       "kto9ybgvnv       US\n",
       "0mj2n4z537       US\n",
       "z7te7g1air      NDF\n",
       "56il3dlb84       US\n",
       "8l7zky3942       US\n",
       "5kj9qbd85v    other\n",
       "l3y5x8vugi      NDF\n",
       "zlv8f1qg2g      NDF\n",
       "woy4x73nen      NDF\n",
       "4db6594ely      NDF\n",
       "x04fkf40pw      NDF\n",
       "jzkbk40w1q      NDF\n",
       "cmjnbto6zg      NDF\n",
       "mrsbt5pb9l       US\n",
       "sjecbinecs       US\n",
       "aynf03zznc      NDF\n",
       "k3uht68h7u       US\n",
       "t55nxx8n0s      NDF\n",
       "              ...  \n",
       "g7ryqvkeii      NDF\n",
       "m4tbin4qln      NDF\n",
       "qsvhjlat8h      NDF\n",
       "icrzw93ddc      NDF\n",
       "84wh2czudf    other\n",
       "bhcu9fsa5j       US\n",
       "xsx2kqtmvu      NDF\n",
       "y8a5sozavm      NDF\n",
       "hj3ko9isnt       US\n",
       "iwpwc2wllf      NDF\n",
       "5lu4h1ksk7      NDF\n",
       "ldvksg216r      NDF\n",
       "ixvti9ek0f      NDF\n",
       "sasvxitm97      NDF\n",
       "3talm5hohz      NDF\n",
       "e0110dx6c9      NDF\n",
       "s4wtj1tq5y      NDF\n",
       "3zi316u9ag      NDF\n",
       "2g5fa9ykpi      NDF\n",
       "qz2xopg27z      NDF\n",
       "zo7nnwawbp      NDF\n",
       "6pxya5gn5y    other\n",
       "a6fj9odooo      NDF\n",
       "yprl259nss       US\n",
       "mmum1j0wlm      NDF\n",
       "efl8dpklm1      NDF\n",
       "s0w86rrm9e      NDF\n",
       "jluu5qcwhg      NDF\n",
       "xif0n17eof       FR\n",
       "zhf38bsj36      NDF\n",
       "Name: country_destination, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.index.isin(sessions_tr[sessions_tr.action == 'new'].user_id), 'country_destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stpcv 1\n",
      "acculynk_bin_check_failed 1\n",
      "rest-of-world 1\n",
      "report 1\n",
      "view 1436\n",
      "acculynk_pin_pad_success 1\n",
      "accept_decline 1\n",
      "my_reservations 203\n",
      "this_hosting_reviews_3000 727\n",
      "add_business_address_colorbox 9\n",
      "events 1\n",
      "host_cancel 1\n",
      "braintree_client_token 89\n",
      "deactivated 1\n",
      "set_minimum_payout_amount 1\n",
      "refund_guest_cancellation 1\n",
      "revert_to_admin 1\n",
      "acculynk_pin_pad_error 4\n",
      "support_phone_numbers 8\n",
      "custom_recommended_destinations 9667\n",
      "sandy 1\n",
      "reset_calendar 2\n",
      "hard_fallback_submit 3\n",
      "unsubscribe 1\n",
      "business_travel 12\n",
      "add_guest_colorbox 5\n",
      "book 82\n",
      "south-america 1\n"
     ]
    }
   ],
   "source": [
    "#find the number of users in test data with an action that is not found in the training sessions data\n",
    "#We should look to find similar items to substitute them\n",
    "for i in a_ignore:\n",
    "    users = sessions_test[sessions_test.action == i].user_id.unique()\n",
    "    if len(users) > 0:\n",
    "        print i, len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-946d0b7ae99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma_ignore\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "actions = list[set(sessions.action.unique())-a_ignore]\n",
    "actions.remove(np.nan)\n",
    "for a in actions:\n",
    "    print sessions[sessions.action == a].user_id.groupby()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#iterate through each action and find those that have more than one action detail/ action type\n",
    "#s = sessions.groupby('action')['action_type'].nunique()\n",
    "#sessions.groupby('action')['action_detail'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3430268.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sessions.loc[0:127, 'secs_elapsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDF      0.560603\n",
       "US       0.297091\n",
       "other    0.058018\n",
       "FR       0.024556\n",
       "IT       0.016707\n",
       "GB       0.012078\n",
       "ES       0.011937\n",
       "CA       0.007073\n",
       "DE       0.004347\n",
       "NL       0.003924\n",
       "AU       0.002303\n",
       "PT       0.001363\n",
       "Name: country_destination, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data.index.isin(sessions[sessions.action== 'personalize'].user_id)].country_destination.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert targets to numerical values\n",
    "targets = train_subset['country_destination']\n",
    "targets_le = preprocessing.LabelEncoder()\n",
    "targets = targets_le.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = train_encoded.values, targets\n",
    "xg_train = xgb.DMatrix(train_X, label = train_Y, missing = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#kfold cross validation\n",
    "kf = KFold(len(train_subset), n_folds=10, shuffle=True, random_state=None)\n",
    "param = {'num_class': 12, 'silent': 1, 'objective': 'multi:softprob'}\n",
    "param['subsample'] = .5\n",
    "param['col_sample_bytree'] = .5\n",
    "param['eta'] = None\n",
    "param['max_delta_step'] = None\n",
    "param['max_depth'] = None\n",
    "\n",
    "#grid search through the following parameter values\n",
    "eta = [.15, .2, .25, .3, .35, .4, .5]\n",
    "num_rounds = range(10,51,5)\n",
    "max_depth = [5, 6, 7]\n",
    "max_delta_step = [0, .5, 1.5, 3, 5]\n",
    "\n",
    "#create data frame for results\n",
    "col_names = ['eta', 'rounds','depth', 'delta']\n",
    "col_names += range(10)\n",
    "res_df = pd.DataFrame(columns=col_names)\n",
    "\n",
    "i = 0\n",
    "for delta in max_delta_step:\n",
    "    param['max_delta_step'] = delta\n",
    "    for depth in max_depth:\n",
    "        print depth\n",
    "        param['max_depth'] = depth\n",
    "        for n in num_rounds:\n",
    "            for e in eta:\n",
    "                param['eta'] = e\n",
    "                cv_error = []\n",
    "                for train_index, test_index in kf:\n",
    "                    #split data\n",
    "                    train_X, train_Y = all_df.iloc[train_index,:], targets[train_index]\n",
    "                    test_X, test_Y = all_df.iloc[test_index,:], targets[test_index]\n",
    "                    xg_train = xgb.DMatrix(train_X, label = train_Y, missing = -1)\n",
    "                    xg_test = xgb.DMatrix(test_X, missing = -1)\n",
    "                    #run xgboost\n",
    "                    bst = xgb.train(param, xg_train, num_boost_round = n)\n",
    "                    #evaluate cross validation error on this split\n",
    "                    pred_prob = bst.predict(xg_test)\n",
    "                    cv_error.append(eval_error(pred_prob, test_Y))\n",
    "                res_df.loc[i] = [e] + [n] + [depth] + [delta] + cv_error\n",
    "                i += 1\n",
    "                res_df.to_pickle('cross_valresults')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.211443</td>\n",
       "      <td>0.036614</td>\n",
       "      <td>0.156609</td>\n",
       "      <td>0.003926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.212702</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.148377</td>\n",
       "      <td>0.002375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.212941</td>\n",
       "      <td>0.037422</td>\n",
       "      <td>0.150010</td>\n",
       "      <td>0.003367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.213027</td>\n",
       "      <td>0.038918</td>\n",
       "      <td>0.152337</td>\n",
       "      <td>0.003187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.214822</td>\n",
       "      <td>0.039571</td>\n",
       "      <td>0.153975</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.214927</td>\n",
       "      <td>0.034995</td>\n",
       "      <td>0.164401</td>\n",
       "      <td>0.003206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.216651</td>\n",
       "      <td>0.039865</td>\n",
       "      <td>0.159727</td>\n",
       "      <td>0.004517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.218139</td>\n",
       "      <td>0.033415</td>\n",
       "      <td>0.169041</td>\n",
       "      <td>0.004995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.220312</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.177505</td>\n",
       "      <td>0.006153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.232952</td>\n",
       "      <td>0.028746</td>\n",
       "      <td>0.194168</td>\n",
       "      <td>0.007831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "5         0.211443        0.036614          0.156609         0.003926\n",
       "9         0.212702        0.040006          0.148377         0.002375\n",
       "8         0.212941        0.037422          0.150010         0.003367\n",
       "7         0.213027        0.038918          0.152337         0.003187\n",
       "6         0.214822        0.039571          0.153975         0.002795\n",
       "3         0.214927        0.034995          0.164401         0.003206\n",
       "4         0.216651        0.039865          0.159727         0.004517\n",
       "2         0.218139        0.033415          0.169041         0.004995\n",
       "1         0.220312        0.028580          0.177505         0.006153\n",
       "0         0.232952        0.028746          0.194168         0.007831"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(columns=['row_above', 'row_below', ])\n",
    "results.sort_values(by= 'test-error-mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ndcg(preds, labels):\n",
    "    \"\"\"Calculate sum of normalzied discounted cumulative gain for the predictions\n",
    "    The correct prediction will have a relevance of 1, incorrect predictions will have a relevance of 0.\n",
    "    Weight the relevance values such that it is reduced logarithmically proportional to it its position     \n",
    "    \n",
    "    Args:\n",
    "        preds: n*5 array of predictor targets\n",
    "        labels: n*1 array targets\n",
    "    Returns:\n",
    "        sum of normalized discounted cumulative gain for all the predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    #find positions where the prediction matches the label\n",
    "    relv_pos = np.where(np.equal(preds, labels))[1]\n",
    "    #weight func: log2(i+1), add one more to adjust for 0-based indexing\n",
    "    total_ndcg = np.sum(1./np.log2(relv_pos+2))\n",
    "    return total_ndcg\n",
    "    \n",
    "def evalerror(cls_prob, dtrain):\n",
    "    \"\"\"find top k predictions from probability matrix and call ndcg to find accuracy of predictions\n",
    "    \n",
    "    Args:\n",
    "        cls_prob: 2D array, probability of each class for each person (n persons by m classes),\n",
    "                  the column index corresponds with class\n",
    "        labels: labels for the n persons\n",
    "    returns:\n",
    "        prediction accuracy using ndcg to evaluate predictions of each AirBNB user\n",
    "    \"\"\"\n",
    "    #determine the top k predictions\n",
    "    labels = dtrain.get_label()\n",
    "    k = 5\n",
    "    top_k = cls_prob.argsort(axis = 1)[:,:k:-1]\n",
    "    #convert true values  and compared with predictions to check for equality\n",
    "    labels = labels[:, None]\n",
    "    return 'error', 1.-ndcg(top_k, labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_NDF():\n",
    "    '''remove users with destination NDF'''\n",
    "\n",
    "    #remove users with destination NDF\n",
    "    train_df = all_df.iloc[train_df['country_destination'] != 'NDF', :]\n",
    "    eta = np.linspace(.15, .30, 10)\n",
    "    param_grid = {}\n",
    "    param_grid['eta'] = eta\n",
    "    param_grid['max_depth'] = [5, 6, 7, 8]\n",
    "    param_grid['subsample'] = [.5, .6, .7, .8]\n",
    "    param_grid['colsample_bytree'] = [.5, .6, .7, .8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = sorted(bst.get_fscore().items(), key = lambda x: x[1], reverse = True)\n",
    "[(feat, all_df.columns[int(feat[1:])], score) for feat, score in features]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
